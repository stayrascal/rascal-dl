{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the default graph for rerun notebook\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Reset the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188c8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = mnist.train.images[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "# y_pred = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv layer\n",
    "conv1_params = {\n",
    "   \"filters\": 256,\n",
    "   \"kernel_size\": 9,\n",
    "   \"strides\": 1,\n",
    "   \"padding\": \"valid\",\n",
    "   \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Capsnes\n",
    "caps1_n_maps = 32\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv2_params = {\n",
    "   \"filters\": caps1_n_maps * caps1_n_dims,\n",
    "   \"kernel_size\": 9,\n",
    "   \"strides\": 2,\n",
    "   \"padding\": \"valid\",\n",
    "   \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_caps = caps1_n_maps * 6 * 6\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims], name=\"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squash = ||s||^2 / (1 + ||s||^2) * s / ||s||\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        \n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit Capsules\n",
    "\n",
    "# Weights\n",
    "caps2_n_caps = 10\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.01\n",
    "\n",
    "W_init = tf.random_normal(shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "                          stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1, name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2, name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1], name=\"caps1_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled, name=\"caps2_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations 3\n",
    "b = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1], dtype=np.float32, name=\"raw_weights\")\n",
    "\n",
    "c = tf.nn.softmax(b, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(c, caps2_predicted, name=\"weighted_predictions\")\n",
    "s = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True, name=\"weighted_sum\")\n",
    "v = squash(s, axis=-2, name=\"caps2_output_round_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 2\n",
    "v_tiled = tf.tile(v, [1, caps1_n_caps, 1, 1, 1], name=\"caps2_output_round_1_tiled\")\n",
    "agreement = tf.matmul(caps2_predicted, v_tiled, transpose_a=True, name=\"agreement\")\n",
    "b = tf.add(b, agreement, name=\"raw_weights_round_2\")\n",
    "c = tf.nn.softmax(b, dim=2, name=\"routing_weights_round_2\")\n",
    "weighted_predictions = tf.multiply(c, caps2_predicted, name=\"weighted_predictions_round_2\")\n",
    "s = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True, name=\"weighted_sum_round_2\")\n",
    "v = squash(s, axis=-2, name=\"caps2_output_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 3\n",
    "v_tiled = tf.tile(v, [1, caps1_n_caps, 1, 1, 1], name=\"caps2_output_round_2_tiled\")\n",
    "agreement = tf.matmul(caps2_predicted, v_tiled, transpose_a=True, name=\"agreement\")\n",
    "b = tf.add(b, agreement, name=\"raw_weights_round_3\")\n",
    "c = tf.nn.softmax(b, dim=2, name=\"routing_weights_round_3\")\n",
    "weighted_predictions = tf.multiply(c, caps2_predicted, name=\"weighted_predictions_round_3\")\n",
    "s = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True, name=\"weighted_sum_round_3\")\n",
    "v = squash(s, axis=-2, name=\"caps2_output_round_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin loss\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "v_norm = tf.norm(v, axis=-2, keep_dims=True, name=\"caps2_output_norm\")\n",
    "\n",
    "FP_raw = tf.square(tf.maximum(0., m_plus - v_norm), name=\"FP_raw\")\n",
    "FP = tf.reshape(FP_raw, shape=(-1, 10), name=\"FP\")\n",
    "\n",
    "FN_raw = tf.square(tf.maximum(0., v_norm - m_minus), name=\"FN_raw\")\n",
    "FN = tf.reshape(FN_raw, shape=(-1, 10), name=\"FN\")\n",
    "\n",
    "L = tf.add(T * FP, lambda_ * (1.0 - T) * FN, name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                             name=\"mask_with_labels\")\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                               lambda: y,        # if True\n",
    "                               lambda: y_pred,   # if False\n",
    "                               name=\"reconstruction_targets\")\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets, depth=caps2_n_caps, name=\"reconstruction_mask\")\n",
    "reconstruction_mask_reshaped = tf.reshape(reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1], name=\"reconstruction_mask_reshaped\")\n",
    "caps2_output_masked = tf.multiply(v, reconstruction_mask_reshaped, name=\"caps2_output_masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                         [-1, caps2_n_caps * caps2_n_dims],\n",
    "                         name=\"decoder_input\")\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                            activation=tf.nn.relu,\n",
    "                            name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                            activation=tf.nn.relu,\n",
    "                            name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                   activation=tf.nn.sigmoid,\n",
    "                                   name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor loss\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                              name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_sum(squared_difference,\n",
    "                                   name=\"reconstruction_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final loss\n",
    "alpha = 0.0005\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "# 全局初始化\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# 计算精度\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "# 用 Adam 优化器\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%) Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,\n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {} Val accuracy: {:.4f}% Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "n_iterations_test = mnist.test.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}% Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "n_samples = 5\n",
    "\n",
    "sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "            [caps2_output, decoder_output, y_pred],\n",
    "            feed_dict={X: sample_images,\n",
    "                       y: np.array([], dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "sample_images = sample_images.reshape(-1, 28, 28)\n",
    "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
